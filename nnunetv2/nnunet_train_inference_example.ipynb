{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c9974ecd",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T03:25:43.988363265Z",
     "start_time": "2024-04-25T03:25:43.152904602Z"
    }
   },
   "outputs": [],
   "source": [
    "#requires you to pip install nnunetv2 and some others\n",
    "#for install details see: https://github.com/MIC-DKFZ/nnUNet\n",
    "import nnunetv2\n",
    "from nnunetv2.dataset_conversion.generate_dataset_json import generate_dataset_json\n",
    "import os,sys\n",
    "import pandas as pd\n",
    "import torch\n",
    "import numpy as np\n",
    "from tqdm import tqdm\n",
    "\n",
    "sys.path.append('/home/hvv/Documents/git_repo') #not required if in the same dir\n",
    "from nnunet_utils.utils import np2sitk, set_env_nnunet, write_envlines_nnunet, assign_trainjobs_to_gpus\n",
    "from nnunet_utils.preprocess import write_as_nnunet, nnunet_directory_structure, preprocess_data\n",
    "from nnunet_utils.run import train_single_model, nnunet_train_shell\n",
    "\n",
    "#root in what folder your nnunet data is stored\n",
    "root = '/media/hvv/ec2480e5-6c18-468c-b971-5271432b386d/hvv/graph_age_data/MRA_CTA_resegmentation/MRA_vesselseg_org_train'\n",
    "datano = '506' #this is an arbitrary number you can choose --> should not be the same as other studies\n",
    "project_name = 'MRAvseg'\n",
    "#task = f'Task{datano}_{project_name}' #this is also something you choose\n",
    "datasetID = f'Dataset{datano}_{project_name}'\n",
    "#where your train (or test) data is stored\n",
    "p_dir = os.path.join(root,'nnUNet_raw',datasetID)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "4c8573f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T20:54:00.169749761Z",
     "start_time": "2024-04-22T20:49:35.150140885Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "all images have a gt\n",
      "------------ environment set ------------\n",
      "Fingerprint extraction...\n",
      "Dataset506_MRAvseg\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer\n",
      "\n",
      "####################\n",
      "verify_dataset_integrity Done. \n",
      "If you didn't see any error messages then your dataset is most likely OK!\n",
      "####################\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:07<00:00,  4.15it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Experiment planning...\n",
      "\n",
      "############################\n",
      "INFO: You are using the old nnU-Net default planner. We have updated our recommendations. Please consider using those instead! Read more here: https://github.com/MIC-DKFZ/nnUNet/blob/master/documentation/resenc_presets.md\n",
      "############################\n",
      "\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.72099999 0.48286401 0.48286401]. \n",
      "Current patch size: (64, 224, 160). \n",
      "Current median shape: [148.54368932 450.97087379 380.58252427]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.74262999 0.49734993 0.49734993]. \n",
      "Current patch size: (64, 224, 160). \n",
      "Current median shape: [144.2171741  437.83579979 369.49759638]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.76490889 0.51227043 0.51227043]. \n",
      "Current patch size: (64, 224, 160). \n",
      "Current median shape: [140.01667388 425.08330077 358.73553047]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.78785615 0.52763854 0.52763854]. \n",
      "Current patch size: (64, 224, 160). \n",
      "Current median shape: [135.93851833 412.70223376 348.28692278]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.81149184 0.5434677  0.5434677 ]. \n",
      "Current patch size: (64, 224, 160). \n",
      "Current median shape: [131.97914401 400.68178035 338.14264348]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.83583659 0.55977173 0.55977173]. \n",
      "Current patch size: (64, 224, 160). \n",
      "Current median shape: [128.13509127 389.01143723 328.29382862]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.86091169 0.57656488 0.57656488]. \n",
      "Current patch size: (64, 224, 160). \n",
      "Current median shape: [124.40300124 377.68100702 318.73187245]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.88673904 0.59386182 0.59386182]. \n",
      "Current patch size: (64, 224, 160). \n",
      "Current median shape: [120.77961285 366.68058934 309.44841985]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.91334121 0.61167768 0.61167768]. \n",
      "Current patch size: (64, 224, 160). \n",
      "Current median shape: [117.26176005 356.00057217 300.43535908]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.94074145 0.63002801 0.63002801]. \n",
      "Current patch size: (64, 224, 160). \n",
      "Current median shape: [113.84636898 345.63162347 291.68481464]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.96896369 0.64892885 0.64892885]. \n",
      "Current patch size: (64, 224, 160). \n",
      "Current median shape: [110.53045532 335.56468298 283.18914043]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [0.9980326  0.66839672 0.66839672]. \n",
      "Current patch size: (64, 224, 160). \n",
      "Current median shape: [107.31112167 325.79095435 274.94091304]\n",
      "Attempting to find 3d_lowres config. \n",
      "Current spacing: [1.02797358 0.68844862 0.68844862]. \n",
      "Current patch size: (64, 224, 160). \n",
      "Current median shape: [104.18555502 316.30189743 266.93292528]\n",
      "2D U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_2d', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 14, 'patch_size': (512, 448), 'median_image_size_in_voxels': array([464.5, 392. ]), 'spacing': array([0.46880001, 0.46880001]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 7, 'features_per_stage': (32, 64, 128, 256, 512, 512, 512), 'conv_op': 'torch.nn.modules.conv.Conv2d', 'kernel_sizes': ((3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3), (3, 3)), 'strides': ((1, 1), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2), (2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm2d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Using <class 'nnunetv2.imageio.simpleitk_reader_writer.SimpleITKIO'> reader/writer\n",
      "3D lowres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_lowres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (64, 224, 160), 'median_image_size_in_voxels': (104, 316, 267), 'spacing': array([1.02797358, 0.68844862, 0.68844862]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': False, 'next_stage': '3d_cascade_fullres'}\n",
      "\n",
      "3D fullres U-Net configuration:\n",
      "{'data_identifier': 'nnUNetPlans_3d_fullres', 'preprocessor_name': 'DefaultPreprocessor', 'batch_size': 2, 'patch_size': (64, 224, 160), 'median_image_size_in_voxels': array([153. , 464.5, 392. ]), 'spacing': array([0.69999999, 0.46880001, 0.46880001]), 'normalization_schemes': ['ZScoreNormalization'], 'use_mask_for_norm': [False], 'resampling_fn_data': 'resample_data_or_seg_to_shape', 'resampling_fn_seg': 'resample_data_or_seg_to_shape', 'resampling_fn_data_kwargs': {'is_seg': False, 'order': 3, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_seg_kwargs': {'is_seg': True, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'resampling_fn_probabilities': 'resample_data_or_seg_to_shape', 'resampling_fn_probabilities_kwargs': {'is_seg': False, 'order': 1, 'order_z': 0, 'force_separate_z': None}, 'architecture': {'network_class_name': 'dynamic_network_architectures.architectures.unet.PlainConvUNet', 'arch_kwargs': {'n_stages': 6, 'features_per_stage': (32, 64, 128, 256, 320, 320), 'conv_op': 'torch.nn.modules.conv.Conv3d', 'kernel_sizes': ((3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3), (3, 3, 3)), 'strides': ((1, 1, 1), (2, 2, 2), (2, 2, 2), (2, 2, 2), (2, 2, 2), (1, 2, 2)), 'n_conv_per_stage': (2, 2, 2, 2, 2, 2), 'n_conv_per_stage_decoder': (2, 2, 2, 2, 2), 'conv_bias': True, 'norm_op': 'torch.nn.modules.instancenorm.InstanceNorm3d', 'norm_op_kwargs': {'eps': 1e-05, 'affine': True}, 'dropout_op': None, 'dropout_op_kwargs': None, 'nonlin': 'torch.nn.LeakyReLU', 'nonlin_kwargs': {'inplace': True}}, '_kw_requires_import': ('conv_op', 'norm_op', 'dropout_op', 'nonlin')}, 'batch_dice': True}\n",
      "\n",
      "Plans were saved to /media/hvv/ec2480e5-6c18-468c-b971-5271432b386d/hvv/graph_age_data/MRA_CTA_resegmentation/MRA_vesselseg_org_train/nnUNet_preprocessed/Dataset506_MRAvseg/nnUNetPlans.json\n",
      "Preprocessing...\n",
      "Preprocessing dataset Dataset506_MRAvseg\n",
      "Configuration: 2d...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [01:07<00:00,  2.24s/it]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: 3d_fullres...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [02:14<00:00,  4.48s/it]\n",
      "  0%|          | 0/30 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configuration: 3d_lowres...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 30/30 [00:46<00:00,  1.55s/it]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "finished preprocessing\n"
     ]
    }
   ],
   "source": [
    "#now the scans have to be preprocessed for training\n",
    "#this is something specifically required by nnUnet\n",
    "#this may take a while, if it fails run again\n",
    "preprocess_data(root, \n",
    "                datano=datano,\n",
    "                datasetID=datasetID, #or task name in old version\n",
    "                dataset_name=project_name,\n",
    "                modalities=['MRA'] #should be a list representing each input channel --> important: should include MR or CT\n",
    "               )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e72a1010",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "ef2fadeb",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-22T21:51:00.174491472Z",
     "start_time": "2024-04-22T21:50:59.988466121Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/hvv/miniconda3/envs/nnunetv2-dev/bin/python\r\n"
     ]
    }
   ],
   "source": [
    "!which python"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "91e13365",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-25T03:25:51.075603396Z",
     "start_time": "2024-04-25T03:25:51.065988026Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": "'/media/hvv/ec2480e5-6c18-468c-b971-5271432b386d/hvv/graph_age_data/MRA_CTA_resegmentation/MRA_vesselseg_org_train/train_jobs.sh'"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "root = '/media/hvv/ec2480e5-6c18-468c-b971-5271432b386d/hvv/graph_age_data/MRA_CTA_resegmentation/MRA_vesselseg_org_train'\n",
    "datano = '508' #this is an arbitrary number you can choose --> should not be the same as other studies\n",
    "project_name = 'MRAvseg_roundrobin'\n",
    "#task = f'Task{datano}_{project_name}' #this is also something you choose\n",
    "datasetID = f'Dataset{datano}_{project_name}'\n",
    "#where your train (or test) data is stored\n",
    "p_dir = os.path.join(root,'nnUNet_raw',datasetID)\n",
    "\n",
    "\n",
    "\n",
    "#there are two options to instantiate training models\n",
    "#1) one-by-one: \n",
    "#train models consecutively for each fold --> run this manually 5 times\n",
    "# train_single_model(gpu=0, #each pc with a single gpu has number 0, selecting another gpu on a server is possible\n",
    "#                    datasetID=datasetID, #defined above\n",
    "#                    resolution='3d_fullres', #can select nnUnet config: ['2d','3d_fullres','3d_lowres', '3d_cascade_fullres'] \n",
    "#                    fold=0, #start with the first fold (number 0)\n",
    "#                   )\n",
    "\n",
    "\n",
    "#2) parallel across gpus: \n",
    "#2a) Create mapping: which GPU does what\n",
    "#Assign jobs to gpus: this is an equal distribution script\n",
    "#it can be wise to first check gpu availability \n",
    "#and then make your own dictionary with distribution dictionary\n",
    "#returns a dictionary with per entry:\n",
    "# gpu_number:[job1, job2] \n",
    "#where each job:\n",
    "#(resolution, fold_number)\n",
    "gpu_dct = assign_trainjobs_to_gpus(num_gpus=1, #total number of GPUs available OR a list of available GPU numbers\n",
    "                           num_folds=1, #number of folds to train (default=5)\n",
    "                           resolutions='3d_fullres' #list of resolutions, any from ['2d','3d_fullres','3d_lowres', '3d_cascade_fullres'] \n",
    "                                )\n",
    "\n",
    "\n",
    "#2b) Create shell script\n",
    "#create a train_job.sh shell script to run multiple folds at the same time\n",
    "#the shell script manages parallel computation across gpus\n",
    "nnunet_train_shell(datasetID=datasetID, #defined above\n",
    "                    root=root,#defined above\n",
    "                    conda_env='/home/hvv/miniconda3/envs/nnunetv2-dev', #path to your environment\n",
    "                    gpu_res_fold_dct=gpu_dct, #is dictionary mapping resolutions, folds and gpus (see above)\n",
    "                    version=2)\n",
    "\n",
    "#2c) Run shell script\n",
    "#Last thing: run the shell script on the server\n",
    "#ssh to server, cd to nnunet folder then: bash train_job.sh\n",
    "#to make sure the server stays running when you close your pc\n",
    "#use tmux: https://tmuxcheatsheet.com/ and https://hamvocke.com/blog/a-quick-and-easy-guide-to-tmux/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "a6305db7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Inference: to predict segmentations using a trained model\n",
    "#After your model is trained these scripts can be used on new cases\n",
    "#there are three ways\n",
    "#1) Run in the python script line by line\n",
    "from nnunet_utils.infv2 import init_predictor, nnunetv2_get_props, nnunetv2_predict\n",
    "\n",
    "model_path = os.path.join(root,'nnUNet_trained_models', datasetID,'nnUNetTrainer__nnUNetPlans__3d_fullres')\n",
    "predictor = init_predictor(model_path)\n",
    "\n",
    "p_data = 'your_test_set_folder'\n",
    "\n",
    "for ID in tqdm(os.listdir(p_data)):\n",
    "    pid = os.path.join(p_crisp,ID)\n",
    "    #input file\n",
    "    file = os.path.join(pid,'scan.nii.gz')\n",
    "    \n",
    "    #output nifti segmentation and also probability output as npy\n",
    "    p_vseg_out = os.path.join(pid,'vesselseg.nii.gz')\n",
    "    p_npy_vseg = os.path.join(pid,'vesselseg')\n",
    "    \n",
    "    #sanity check to not run the same stuff twice\n",
    "    if os.path.exists(p_vseg_out) and os.path.exists(p_npy_vseg+'.npy'):\n",
    "        continue\n",
    "    #running this for loop can take long\n",
    "    #so a try-except to prevent stopping somewhere in the middle\n",
    "    try:\n",
    "        mra = sitk.ReadImage(file)\n",
    "        props = nnunetv2_get_props(mra)\n",
    "        mra_inp = np.expand_dims(sitk.GetArrayFromImage(mra),0)\n",
    "        seg = nnunetv2_predict(mra_inp,props,predictor, return_probabilities=True)\n",
    "\n",
    "        sitk.WriteImage(np2sitk(seg[0],mra),p_vseg_out)\n",
    "\n",
    "        np.save(p_npy_vseg,seg[1])\n",
    "    except:\n",
    "        continue\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a26e9e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#2) Create a file with all input images similar to the imagesTr (but now imagesTs)\n",
    "#and run it in a batch at once\n",
    "from nnunet_utils.run import nnunet_inference_on_dir\n",
    "\n",
    "#first put all scans in the test folder:\n",
    "#nnUNet_raw/DatasetID/imagesTs\n",
    "test_img_dir = os.path.join(p_dir,'imagesTs')\n",
    "for ID in os.listdir(p_data):\n",
    "    pid = os.path.join(p_data,ID)\n",
    "    p_img = os.path.join(pid,'scan_test.nii.gz')\n",
    "    #this function copies using shutil (=really fast)\n",
    "    copy_inference_image(p_img, test_img_dir)\n",
    "    #as an alternative you can read with sitk and write\n",
    "    #which is slower but still ok in speed\n",
    "    \n",
    "#with the data in the right order\n",
    "#it is now possible to run the inference commands\n",
    "model_path = os.path.join(root,'nnUNet_trained_models', datasetID,'nnUNetTrainer__nnUNetPlans__3d_fullres')\n",
    "seg_test_pred_dir = os.path.join(p_dir,'predictions')\n",
    "if not os.path.exists(seg_test_pred_dir):\n",
    "    os.makedirs(seg_test_pred_dir)\n",
    "    \n",
    "nnunet_inference_on_dir(model_path=model_path, #path to the trained folds\n",
    "                        dir_input_images=test_img_dir, #where the imagesTs (inference images) are stored\n",
    "                        dir_output_seg=seg_test_pred_dir, #where you want to store the predictions\n",
    "                        resolution='fullres', #can select nnUnet config (must correspond with model_path): ['2d','3d_fullres','3d_lowres', '3d_cascade_fullres'] \n",
    "                        save_probs=True #if you want predicted probabilities\n",
    "                        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a6026d5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#3) For large datasets it can be useful to run inference on multiple GPUs\n",
    "#Similar to training: create a gpu_dct defining the distribution\n",
    "#of images across GPUs and run it using a shell script\n",
    "from nnunet_utils.run import nnunetv2_inference_shell\n",
    "\n",
    "#input parameters\n",
    "path_images_in = 'directory/with/inference/images'\n",
    "path_segs_out = 'directory/to/output/segmentation/folder'\n",
    "p_model = 'path/to/nnunet/model/nnUNet_trained_models/Datasetxxx_name/nnUNetTrainer__nnUNetPlans__3d_fullres'\n",
    "conda_env = 'miniconda3/envs/nnunetv2' #contains pip installed nnunetv2\n",
    "root = 'root/to/nnunet/dir/to/set/path/variables'\n",
    "\n",
    "gpu_dct = gpu_distributed_inference(images=path_images_in, #input images for inference\n",
    "                                      num_gpus=1, #int or list defining available gpus\n",
    "                                      resolutions=['fullres_3d'],\n",
    "                                      separate_folders=False, #if True GPU batches of images are copied to separate folders\n",
    "                                      seg_dir=None, #pass path_segs_out to skip certain \n",
    "                                    )\n",
    "\n",
    "job_file = nnunetv2_inference_shell(root=root,\n",
    "                                    conda_env=conda_env,\n",
    "                                    gpu_dct=gpu_dct,  # is created with utils function assign_to_gpu\n",
    "                                    path_model=p_model,\n",
    "                                    dir_output_seg=path_segs_out,\n",
    "                                    return_probabilities=True,\n",
    "                                    path_nnunet_utils='path/to/nnunet_utils',\n",
    "                                    version=2)\n",
    "print(job_file)\n",
    "#run the job_file using bash"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
